{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dense model\n",
    "\n",
    "![dense_model.png](attachment:dense_model.png width=\"300\")\n",
    "<img src=\"attachment:image.png\" width=\"400\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from util import dataset_fn\n",
    "from dense_model import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_CORPUS_PATH = './data/ratings_train.cleaned.txt'\n",
    "TEST_CORPUS_PATH = './data/ratings_test.cleaned.txt'\n",
    "VOCAB_PATH = 'Word2vec.vocab'\n",
    "VOCAB_MODEL_PATH = 'Word2vec.model'\n",
    "MODEL_PATH = 'Dense.model'\n",
    "\n",
    "MAX_LEN = 100\n",
    "BATCH_SIZE = 128\n",
    "LEARNING_RATE = 0.001\n",
    "TRAIN_STEPS = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now building model\n"
     ]
    }
   ],
   "source": [
    "train_dataset = dataset_fn(TRAIN_CORPUS_PATH, VOCAB_PATH, MAX_LEN, BATCH_SIZE)\n",
    "test_dataset = dataset_fn(TEST_CORPUS_PATH, VOCAB_PATH, MAX_LEN, BATCH_SIZE)\n",
    "\n",
    "iters = tf.data.Iterator.from_structure(train_dataset.output_types,\n",
    "                                        train_dataset.output_shapes)\n",
    "features = iters.get_next()\n",
    "\n",
    "# create the initialisation operations\n",
    "train_init_op = iters.make_initializer(train_dataset)\n",
    "test_init_op = iters.make_initializer(test_dataset)\n",
    "\n",
    "print(\"Now building model\")\n",
    "model = Model(VOCAB_MODEL_PATH, MAX_LEN, LEARNING_RATE)\n",
    "loss, acc, opt = model.build_optimizer(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## for tensorboard\n",
    "train_loss_graph = tf.placeholder(shape=None, dtype=tf.float32)\n",
    "train_acc_graph = tf.placeholder(shape=None, dtype=tf.float32)\n",
    "test_loss_graph = tf.placeholder(shape=None, dtype=tf.float32)\n",
    "test_acc_graph = tf.placeholder(shape=None, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now training\n",
      "step: 11 train_loss: 0.6033951504663988 train_acc: 0.6626420454545454\n",
      "step: 21 train_loss: 0.5394948763506753 train_acc: 0.7276785714285714\n",
      "step: 31 train_loss: 0.5057595747132455 train_acc: 0.7550403225806451\n",
      "step: 41 train_loss: 0.4961309709200045 train_acc: 0.7682926829268293\n",
      "step: 51 train_loss: 0.48953339106896343 train_acc: 0.7766544117647058\n",
      "step: 61 train_loss: 0.47748040908672773 train_acc: 0.7820184426229508\n",
      "step: 71 train_loss: 0.47311739224783134 train_acc: 0.7869718309859155\n",
      "step: 81 train_loss: 0.4672812418437298 train_acc: 0.7910879629629629\n",
      "step: 91 train_loss: 0.46103066500726636 train_acc: 0.7958447802197802\n",
      "step: 101 train_loss: 0.4561078223851648 train_acc: 0.7991955445544554\n",
      "step: 111 train_loss: 0.4509219113770906 train_acc: 0.8020129504504504\n",
      "step: 121 train_loss: 0.44989592625089914 train_acc: 0.8032670454545454\n",
      "step: 131 train_loss: 0.44772606496592515 train_acc: 0.8048664122137404\n",
      "step: 141 train_loss: 0.4459563897433856 train_acc: 0.8064051418439716\n",
      "step: 151 train_loss: 0.4416143888274565 train_acc: 0.8083609271523179\n",
      "step: 161 train_loss: 0.4399026928481108 train_acc: 0.8095399844720497\n",
      "step: 171 train_loss: 0.44011462623612924 train_acc: 0.8093932748538012\n",
      "step: 181 train_loss: 0.43703360254593315 train_acc: 0.8109461325966851\n",
      "step: 191 train_loss: 0.43676538773232104 train_acc: 0.8114365183246073\n",
      "step: 201 train_loss: 0.4366721691776864 train_acc: 0.8116060323383084\n",
      "step: 211 train_loss: 0.4345481099110644 train_acc: 0.812759182464455\n",
      "step: 221 train_loss: 0.4342049121586985 train_acc: 0.8127121040723982\n",
      "step: 231 train_loss: 0.4327993681936553 train_acc: 0.8132440476190477\n",
      "step: 241 train_loss: 0.43258057491413293 train_acc: 0.8133104253112033\n",
      "step: 251 train_loss: 0.4315533309106333 train_acc: 0.8143052788844621\n",
      "step: 261 train_loss: 0.4307759696496401 train_acc: 0.8144456417624522\n",
      "step: 271 train_loss: 0.4296683243499911 train_acc: 0.8147197878228782\n",
      "step: 281 train_loss: 0.4289905240103019 train_acc: 0.8146685943060499\n",
      "step: 291 train_loss: 0.4283977390564594 train_acc: 0.8148893900343642\n",
      "step: 301 train_loss: 0.4276432793995867 train_acc: 0.8151993355481728\n",
      "step: 311 train_loss: 0.427101555648724 train_acc: 0.8157154340836013\n",
      "step: 321 train_loss: 0.42668494610028845 train_acc: 0.8161993769470405\n",
      "step: 331 train_loss: 0.42662420670791695 train_acc: 0.8160404078549849\n",
      "step: 341 train_loss: 0.42626117296582444 train_acc: 0.8166697214076246\n",
      "step: 351 train_loss: 0.4271259835133186 train_acc: 0.8165286680911681\n",
      "step: 361 train_loss: 0.4278289183685324 train_acc: 0.8159193213296398\n",
      "step: 371 train_loss: 0.4276432521099029 train_acc: 0.8157850404312669\n",
      "step: 381 train_loss: 0.42820339135610525 train_acc: 0.8153502296587927\n",
      "step: 391 train_loss: 0.4279538502778544 train_acc: 0.8154371803069054\n",
      "step: 401 train_loss: 0.4276926666126584 train_acc: 0.8154613466334164\n",
      "step: 411 train_loss: 0.4273894497367877 train_acc: 0.8159405413625304\n",
      "step: 421 train_loss: 0.42733219032332903 train_acc: 0.8160443883610451\n",
      "step: 431 train_loss: 0.4273833257001403 train_acc: 0.8162340487238979\n",
      "step: 441 train_loss: 0.42792903491699236 train_acc: 0.815812783446712\n",
      "step: 451 train_loss: 0.42767959515958565 train_acc: 0.8156873614190687\n",
      "step: 461 train_loss: 0.4275621721387685 train_acc: 0.8157368492407809\n",
      "step: 471 train_loss: 0.42700064549273997 train_acc: 0.8162154989384289\n",
      "step: 481 train_loss: 0.4261948158983877 train_acc: 0.816722972972973\n",
      "step: 491 train_loss: 0.4263676542128662 train_acc: 0.816684699592668\n",
      "step: 501 train_loss: 0.4268401946255309 train_acc: 0.8168818612774451\n",
      "step: 511 train_loss: 0.4267343903824308 train_acc: 0.8169184197651663\n",
      "step: 521 train_loss: 0.4265786298977894 train_acc: 0.8172084932821497\n",
      "step: 531 train_loss: 0.4265885582639224 train_acc: 0.816972693032015\n",
      "step: 541 train_loss: 0.42669560502725695 train_acc: 0.816817814232902\n",
      "step: 551 train_loss: 0.4261152149328519 train_acc: 0.8171506352087115\n",
      "step: 561 train_loss: 0.4257581195198066 train_acc: 0.8174994429590018\n",
      "step: 571 train_loss: 0.42592466827449366 train_acc: 0.8175623905429071\n",
      "step: 581 train_loss: 0.42604585481797974 train_acc: 0.8176366179001722\n",
      "step: 591 train_loss: 0.4255661680512824 train_acc: 0.817985934856176\n",
      "step: 601 train_loss: 0.4254095015827312 train_acc: 0.8179596505823628\n",
      "step: 611 train_loss: 0.4247802136475053 train_acc: 0.8180876636661211\n",
      "step: 621 train_loss: 0.42493582558900644 train_acc: 0.8180480072463768\n",
      "step: 631 train_loss: 0.4248392021315978 train_acc: 0.8180962757527733\n",
      "step: 641 train_loss: 0.4243939291110463 train_acc: 0.8182405421216848\n",
      "step: 651 train_loss: 0.42463025198920346 train_acc: 0.8181763632872504\n",
      "step: 661 train_loss: 0.42462156782893296 train_acc: 0.8183741490166414\n",
      "step: 671 train_loss: 0.42417731588004065 train_acc: 0.8185660394932935\n",
      "step: 681 train_loss: 0.4241742026525797 train_acc: 0.8186719897209985\n",
      "step: 691 train_loss: 0.42378849019707543 train_acc: 0.8188314037626628\n",
      "step: 701 train_loss: 0.42350004500737376 train_acc: 0.8188636768901569\n",
      "step: 711 train_loss: 0.4236541969699028 train_acc: 0.8188840541490858\n",
      "step: 721 train_loss: 0.4238676311817645 train_acc: 0.8188821948682385\n",
      "step: 731 train_loss: 0.4239724959704194 train_acc: 0.8189445109439124\n",
      "step: 741 train_loss: 0.42385248093791655 train_acc: 0.8190578609986505\n",
      "step: 751 train_loss: 0.42415690080779844 train_acc: 0.8187832889480693\n",
      "step: 761 train_loss: 0.4243062409167221 train_acc: 0.8186083278580815\n",
      "step: 771 train_loss: 0.4240484479259115 train_acc: 0.8188330901426718\n",
      "step: 781 train_loss: 0.42400473669152255 train_acc: 0.8189420614596671\n",
      "step: 791 train_loss: 0.4240992239920138 train_acc: 0.8188013590391909\n",
      "step: 801 train_loss: 0.42380273423986636 train_acc: 0.8190055399500624\n",
      "step: 811 train_loss: 0.42358455613126883 train_acc: 0.8191083538840938\n",
      "step: 821 train_loss: 0.4236435921052777 train_acc: 0.8190468940316687\n",
      "step: 831 train_loss: 0.4236052989170726 train_acc: 0.8190527226233454\n",
      "step: 841 train_loss: 0.4233989862638762 train_acc: 0.8191048602853745\n",
      "step: 851 train_loss: 0.4232444027756132 train_acc: 0.8191557726204466\n",
      "step: 861 train_loss: 0.42341557425488996 train_acc: 0.8192599448315911\n",
      "step: 871 train_loss: 0.4233622677564347 train_acc: 0.8192989380022963\n",
      "step: 881 train_loss: 0.4236241279002892 train_acc: 0.8192306328036323\n",
      "step: 891 train_loss: 0.42366764223669245 train_acc: 0.819120019640853\n",
      "step: 901 train_loss: 0.42363828384254404 train_acc: 0.8191245837957825\n",
      "step: 911 train_loss: 0.4233796922357101 train_acc: 0.8191376234906695\n",
      "step: 921 train_loss: 0.4232430605300733 train_acc: 0.8191164495114006\n",
      "step: 931 train_loss: 0.42334650704991295 train_acc: 0.819078947368421\n",
      "step: 941 train_loss: 0.4232058708776703 train_acc: 0.8192664054197663\n",
      "step: 951 train_loss: 0.4231867577437973 train_acc: 0.8192034700315457\n",
      "step: 961 train_loss: 0.42323827759036164 train_acc: 0.8191824921956296\n",
      "step: 971 train_loss: 0.42335676904441644 train_acc: 0.8191539006179197\n",
      "step: 981 train_loss: 0.4232608181074125 train_acc: 0.8190781090723751\n",
      "step: 991 train_loss: 0.42348824232425747 train_acc: 0.8190826816347124\n",
      "step: 1001 train_loss: 0.4231184240166362 train_acc: 0.8193447177822177\n",
      "step: 1011 train_loss: 0.4230772511836447 train_acc: 0.8193465628090999\n",
      "step: 1021 train_loss: 0.4229080837573874 train_acc: 0.8193330680705191\n",
      "step: 1031 train_loss: 0.4228572212123501 train_acc: 0.8193122575169738\n",
      "step: 1041 train_loss: 0.42265237978052106 train_acc: 0.8194269332372719\n",
      "step: 1051 train_loss: 0.42258322916634306 train_acc: 0.8195319933396765\n",
      "step: 1061 train_loss: 0.42248601735368524 train_acc: 0.8196792530631479\n",
      "step: 1071 train_loss: 0.4225201489600369 train_acc: 0.8195903361344538\n",
      "step: 1081 train_loss: 0.42256739363418916 train_acc: 0.8196186979648473\n",
      "step: 1091 train_loss: 0.4222786180422352 train_acc: 0.8197467919340055\n",
      "step: 1101 train_loss: 0.422266897643078 train_acc: 0.8197235467756585\n",
      "step: 1111 train_loss: 0.42237834282333414 train_acc: 0.8196866561656165\n",
      "step: 1121 train_loss: 0.42236673722939233 train_acc: 0.8197201159678859\n",
      "step: 1131 train_loss: 0.42241575900270917 train_acc: 0.8198427829354553\n",
      "step: 1141 train_loss: 0.42264566734420117 train_acc: 0.8197373466257669\n",
      "step: 1151 train_loss: 0.4226906614962295 train_acc: 0.8196948305821026\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 1161 train_loss: 0.4227524366130303 train_acc: 0.8196934216192937\n",
      "step: 1171 train_loss: 0.4228201711361068 train_acc: 0.8196319918872759\n",
      "step: 1181 train_loss: 0.42286133690469857 train_acc: 0.8197039055884844\n",
      "step: 1191 train_loss: 0.4230417038941964 train_acc: 0.8196762174643157\n",
      "step: 1201 train_loss: 0.4229446557985555 train_acc: 0.8197270503746877\n",
      "step: 1211 train_loss: 0.42290729257215853 train_acc: 0.8198028488852188\n",
      "step: 1221 train_loss: 0.4228308087338394 train_acc: 0.8198646089271089\n",
      "step: 1231 train_loss: 0.42279765247136575 train_acc: 0.8199634443541836\n",
      "step: 1241 train_loss: 0.42263848941524024 train_acc: 0.8200103243352136\n",
      "step: 1251 train_loss: 0.4225582443267036 train_acc: 0.8201189048760992\n",
      "step: 1261 train_loss: 0.42223254798613874 train_acc: 0.8202815226011102\n",
      "step: 1271 train_loss: 0.4220616096684916 train_acc: 0.8203063532651456\n",
      "step: 1281 train_loss: 0.42213183988080555 train_acc: 0.8203490925058547\n",
      "step: 1291 train_loss: 0.4219343454268993 train_acc: 0.8203609120836561\n",
      "step: 1301 train_loss: 0.42186389910450905 train_acc: 0.8204986548808608\n",
      "step: 1311 train_loss: 0.42191303937968 train_acc: 0.820437643020595\n",
      "step: 1321 train_loss: 0.42183188790628895 train_acc: 0.8205313209689629\n",
      "step: 1331 train_loss: 0.42181544116705905 train_acc: 0.8205942430503381\n",
      "step: 1341 train_loss: 0.4218245250888941 train_acc: 0.8206037938105891\n",
      "step: 1351 train_loss: 0.4216514590887738 train_acc: 0.820653682457439\n",
      "step: 1361 train_loss: 0.421533839721 train_acc: 0.8206626561351947\n",
      "step: 1371 train_loss: 0.4216023608770447 train_acc: 0.8205689277899344\n",
      "step: 1381 train_loss: 0.4213676622904875 train_acc: 0.8207763848660391\n",
      "step: 1391 train_loss: 0.4210054688878748 train_acc: 0.8210257907979871\n",
      "step: 1401 train_loss: 0.4211439218885298 train_acc: 0.8209593593861527\n",
      "step: 1411 train_loss: 0.42096504619745057 train_acc: 0.821098733167966\n",
      "step: 1421 train_loss: 0.42089516098527824 train_acc: 0.821093200211119\n",
      "step: 1431 train_loss: 0.4207758361605145 train_acc: 0.8211860150244584\n",
      "step: 1441 train_loss: 0.4206739548673901 train_acc: 0.8211962179042331\n",
      "step: 1451 train_loss: 0.42071513224683244 train_acc: 0.821125516884907\n",
      "step: 1461 train_loss: 0.42069276532924477 train_acc: 0.8212055099247091\n",
      "step: 1471 train_loss: 0.42063453627394465 train_acc: 0.8213215924541128\n",
      "step: 1481 train_loss: 0.42050876444775376 train_acc: 0.8213939061444969\n",
      "step: 1491 train_loss: 0.42059406748080236 train_acc: 0.8213080566733736\n",
      "step: 1501 train_loss: 0.4205256888145292 train_acc: 0.8213638824117255\n",
      "step: 1511 train_loss: 0.420622858304523 train_acc: 0.8213207313037724\n",
      "step: 1521 train_loss: 0.4205750302411004 train_acc: 0.8213397846811308\n",
      "step: 1531 train_loss: 0.42064091911664747 train_acc: 0.8213024575440888\n",
      "step: 1541 train_loss: 0.42060421920689106 train_acc: 0.8213467310188189\n",
      "step: 1551 train_loss: 0.42056649373778215 train_acc: 0.8213450999355255\n",
      "step: 1561 train_loss: 0.4207722589344951 train_acc: 0.821283432094811\n",
      "step: 1571 train_loss: 0.4207813135193534 train_acc: 0.8213120623806492\n",
      "step: 1581 train_loss: 0.4208653845189871 train_acc: 0.8211525537634409\n",
      "step: 1591 train_loss: 0.42068427106181755 train_acc: 0.8212111093651792\n",
      "step: 1601 train_loss: 0.42063115817319596 train_acc: 0.8211566989381637\n",
      "step: 1611 train_loss: 0.4207299210542777 train_acc: 0.8210496198013656\n",
      "step: 1621 train_loss: 0.42058137932506184 train_acc: 0.821112546267736\n",
      "step: 1631 train_loss: 0.4206398938017926 train_acc: 0.8210980610055181\n",
      "step: 1641 train_loss: 0.4205686397700685 train_acc: 0.8210980347349177\n",
      "step: 1651 train_loss: 0.42040620779427956 train_acc: 0.8211311326468806\n",
      "step: 1661 train_loss: 0.42038884062784254 train_acc: 0.821224977423239\n",
      "step: 1671 train_loss: 0.42034409505959974 train_acc: 0.8212382181328546\n",
      "step: 1681 train_loss: 0.4202938614715642 train_acc: 0.8212745389649019\n",
      "step: 1691 train_loss: 0.420122832870568 train_acc: 0.8213473905972797\n",
      "step: 1701 train_loss: 0.42016615396664464 train_acc: 0.8213550852439742\n",
      "step: 1711 train_loss: 0.42011726623665585 train_acc: 0.8213900862068966\n",
      "step: 1721 train_loss: 0.4201099319661654 train_acc: 0.8212930345729227\n",
      "step: 1731 train_loss: 0.4198215312691936 train_acc: 0.821485954650491\n",
      "step: 1741 train_loss: 0.4197655828912528 train_acc: 0.8215734491671454\n",
      "step: 1751 train_loss: 0.4197725684965494 train_acc: 0.8215260922330098\n",
      "step: 1761 train_loss: 0.41989510691281007 train_acc: 0.8215325099375355\n",
      "step: 1771 train_loss: 0.41990815309196594 train_acc: 0.8216094367588933\n",
      "step: 1781 train_loss: 0.4196673259850234 train_acc: 0.821760071588995\n",
      "step: 1791 train_loss: 0.4197143399635551 train_acc: 0.8217432649357901\n",
      "step: 1801 train_loss: 0.4196894297263544 train_acc: 0.8217570099944476\n",
      "step: 1811 train_loss: 0.4199523395395358 train_acc: 0.8216454997239094\n",
      "step: 1821 train_loss: 0.4198690066947707 train_acc: 0.8216725013728721\n",
      "step: 1831 train_loss: 0.41982269861670807 train_acc: 0.8217717435827416\n",
      "step: 1841 train_loss: 0.41989432782792707 train_acc: 0.8216577267789245\n",
      "step: 1851 train_loss: 0.4198693498478008 train_acc: 0.8216589005942734\n",
      "step: 1861 train_loss: 0.4198537286509115 train_acc: 0.821681051853842\n",
      "step: 1871 train_loss: 0.4197830651164501 train_acc: 0.8217321953500801\n",
      "step: 1881 train_loss: 0.4197409610397191 train_acc: 0.821757874800638\n",
      "step: 1891 train_loss: 0.41975732074409233 train_acc: 0.8217378371232152\n",
      "step: 1901 train_loss: 0.41965403050764305 train_acc: 0.8218248619147817\n",
      "step: 1911 train_loss: 0.4196228656171193 train_acc: 0.8218414769754055\n",
      "step: 1921 train_loss: 0.4197015722147938 train_acc: 0.821813183237897\n",
      "step: 1931 train_loss: 0.41974542298074957 train_acc: 0.821781136716727\n",
      "step: 1941 train_loss: 0.4197591224753445 train_acc: 0.8217453954147347\n",
      "step: 1951 train_loss: 0.4196892527511094 train_acc: 0.8217420553562276\n",
      "step: 1961 train_loss: 0.41980701786775115 train_acc: 0.8216391509433962\n",
      "step: 1971 train_loss: 0.4197218048880997 train_acc: 0.8217037671232876\n",
      "step: 1981 train_loss: 0.41968605102823575 train_acc: 0.8216928003533569\n",
      "step: 1991 train_loss: 0.4197758725843856 train_acc: 0.8216270090406831\n",
      "step: 2001 train_loss: 0.4198633180237722 train_acc: 0.8216946214392804\n",
      "Now for test data\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-9f2ad84a3fea>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     47\u001b[0m                 \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m                     \u001b[0mn_test_step\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m                     \u001b[0mbatch_test_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_test_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m                     \u001b[0mtest_loss_\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mbatch_test_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m                     \u001b[0mtest_acc_\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mbatch_test_acc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/jbk4860/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/jbk4860/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1150\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1152\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1153\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/jbk4860/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1328\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1329\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/jbk4860/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1332\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1333\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1334\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1335\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1336\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/jbk4860/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1317\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1319\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/jbk4860/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1405\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1409\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print(\"Now training\")\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "ckpt = tf.train.get_checkpoint_state(\"./model\")\n",
    "\n",
    "summary_train_loss = tf.summary.scalar(\"train_loss\", train_loss_graph)\n",
    "summary_train_acc = tf.summary.scalar(\"train_acc\", train_acc_graph)\n",
    "summary_test_loss = tf.summary.scalar(\"test_loss\", test_loss_graph)\n",
    "summary_test_acc = tf.summary.scalar(\"test_acc\", test_acc_graph)\n",
    "merged_train = tf.summary.merge([summary_train_loss, summary_train_acc])\n",
    "merged_test = tf.summary.merge([summary_test_loss, summary_test_acc])\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    sess.run(train_init_op)\n",
    "    sess.run(tf.tables_initializer())\n",
    "\n",
    "    n_train_step = 0\n",
    "    train_loss_, train_acc_ = 0., 0.\n",
    "    test_loss_, test_acc_ = 0., 0.\n",
    "    best_loss = 1e8\n",
    "    writer = tf.summary.FileWriter('./tensorboard/graph', sess.graph)\n",
    "\n",
    "    for step in range(TRAIN_STEPS):\n",
    "        n_train_step += 1\n",
    "        batch_train_loss, batch_train_acc, _ = sess.run([loss, acc, opt])\n",
    "        train_loss_ += batch_train_loss\n",
    "        train_acc_ += batch_train_acc\n",
    "        train_loss = train_loss_ / n_train_step\n",
    "        train_acc = train_acc_ / n_train_step\n",
    "        \n",
    "        if step % 10 == 0 and step > 0:\n",
    "            print(f\"step: {step + 1} train_loss: {train_loss} train_acc: {train_acc}\")\n",
    "\n",
    "        if step % 100 == 0 and step > 0:\n",
    "            summary = sess.run(merged_train,\n",
    "                               feed_dict={train_loss_graph: train_loss, train_acc_graph: train_acc})\n",
    "            writer.add_summary(summary, step)\n",
    "\n",
    "        if step % 2000 == 0 and step > 0:\n",
    "            print(\"Now for test data\")\n",
    "            sess.run(test_init_op)\n",
    "            n_test_step = 0\n",
    "\n",
    "            try:\n",
    "                while True:\n",
    "                    n_test_step += 1\n",
    "                    batch_test_loss, batch_test_acc = sess.run([loss, acc])\n",
    "                    test_loss_ += batch_test_loss\n",
    "                    test_acc_ += batch_test_acc\n",
    "\n",
    "            except tf.errors.OutOfRangeError:\n",
    "                pass\n",
    "\n",
    "            test_loss = test_loss_ / n_test_step\n",
    "            test_acc = test_acc_ / n_test_step\n",
    "\n",
    "            summary = sess.run(merged_test, feed_dict={test_loss_graph: test_loss, test_acc_graph: test_loss})\n",
    "            writer.add_summary(summary, step)\n",
    "            print(f\"step: {step + 1} test_loss: {test_loss} test_acc: {test_acc}\")\n",
    "\n",
    "            if test_loss < best_loss or step % 2000 == 0:\n",
    "                save_path = saver.save(sess, \"./model/\" + MODEL_PATH)\n",
    "                best_loss = test_loss\n",
    "\n",
    "            sess.run(train_init_op)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensorboard\n",
    "\n",
    "- tensorboard --logdir=./tensorboard/graph/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
